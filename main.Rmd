---
title: "现代统计软件论文"
author:
  - 吴宇翀
  - 高思琴
  - 陈蔚
documentclass: ctexart
output:
  rticles::ctex:
    fig_caption: yes
    number_sections: yes
    toc: yes
classoption: "hyperref,"
---

```{r}
library(caret)
library(kernlab)
library(pROC)
```

# 摘要

识别与预测信用卡是否将会逾期（信用卡风控部门）

> 待完善

# 背景

识别与预测信用卡是否将会逾期（信用卡风控部门）

> 待完善

# 数据集说明

```{r}
dat = read.csv("data.csv")
dat = dat[,-1]
dat$SeriousDlqin2yrs = as.factor(dat$SeriousDlqin2yrs)
```

SeriousDlqin2yrs: 是否逾期。
RevolvingUtilizationOfUnsecuredLines：信用卡和个人信贷额度的总余额（百分比）*怀疑此翻译有误*
age：年龄
NumberOfTime30-59DaysPastDueNotWorse：过去2年，借款人逾期30-59天的次数
DebtRatio：负债比率（百分比）
MonthlyIncome：月收入
NumberOfOpenCreditLinesAndLoans：未偿还贷款数量（汽车贷款或抵押贷款等分期付款）和信贷额度（如信用卡）。
NumberOfTimes90DaysLate：借款人逾期90天或以上的次数。
NumberRealEstateLoansOrLines：抵押贷款和房地产贷款的数量。
NumberOfTime60-89DaysPastDueNotWorse：过去2年，借款人逾期60-89天的次数
NumberOfDependents：家庭中的家属人数（配偶，子女等）

> 数据集表格 dictionary


到英文网站上翻译 ^[数据来源: https://www.kaggle.com/c/GiveMeSomeCredit/overview]

> 待完善

## 异常值处理

1. 由于样本量已经足够大，我们删除所有包含缺失值的观测。
2. 由于**信用卡和个人信贷额度的总余额**和**负债比率**两个指标为百分比，我们将这两个指标中小于0的数据调整为0，将大于1的数据调整为1。

```{r}
dat$RevolvingUtilizationOfUnsecuredLines[which(dat$RevolvingUtilizationOfUnsecuredLines < 0)] = 0
dat$RevolvingUtilizationOfUnsecuredLines[which(dat$RevolvingUtilizationOfUnsecuredLines > 1)] = 1
dat$DebtRatio[which(dat$DebtRatio < 0)] = 0
dat$DebtRatio[which(dat$DebtRatio > 1)] = 1
dat_complete = dat[complete.cases(dat),]
```

## 基准正确率

```{r}
summary(dat_complete$SeriousDlqin2yrs)
1 - 8357 / 139974
```

# 模型选择

## 抽样

由于数据集样本量过大，难以完成较为复杂的模型求解。 ^[由于条件所限，本研究小组只有单台计算机的算力。在有分布式计算的环境下，可能不需要此步操作。]


```{r}
set.seed(1)
inTraining <- createDataPartition(dat_complete$SeriousDlqin2yrs, p = .01, list = FALSE)
training <- dat_complete[inTraining,]
```


Kappa 统计量（Cohen 1960）最初是一个用来评估两个估价者评估结果的一致性，同时也考虑到了由偶然情况引起的准确性误差。

$$\mathrm{Kappa}=\frac{O-E}{1-E}$$

> 在上式中，O是观测的准确性，E是基于混淆矩阵边缘计数得到的期望准确性。该统计量取值在-1和1之间;0值表示观测类与预测类之间没有一致性，1值表示模型的预测与观测类完全一致。负值表示预测与事实相反，但在建立预测模型过程中绝对值大的负值很少出现。当各类分布相同时，总精确度与 Kappa是成比例的。取决于具体情况，Kappa值在0.30到0.50之间代表合理的一致性。（Agresti 2002）

> 这段话要进行语序修改，规避查重。

我们使用 Kappa 和准确率作为模型的评价指标。

## GBM

```{r include=FALSE}
fitControl <- trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           ## repeated ten times
                           repeats = 5,
                           summaryFunction = twoClassSummary)

set.seed(1)
gbm <- train(SeriousDlqin2yrs ~ ., data = training, 
                 method = "gbm", 
                 trControl = fitControl)
```

## SVM

```{r}
set.seed(1)
svm <- train(SeriousDlqin2yrs ~ ., data = training, 
                 method = "svmRadial", 
                 trControl = fitControl,
            tuneLength = 10)
svm
svm$results

trellis.par.set(caretTheme())
plot(svm)

trellis.par.set(caretTheme())
plot(svm, metric = "Kappa")

trellis.par.set(caretTheme())
densityplot(svm, pch = "|")
```

## Logit

```{r}
set.seed(1)
logit <- train(SeriousDlqin2yrs ~ ., data = training, 
                 method = "glm", 
                 trControl = fitControl)
logit
logit$results

trellis.par.set(caretTheme())
plot(logit)

trellis.par.set(caretTheme())
plot(logit, metric = "Kappa")

trellis.par.set(caretTheme())
densityplot(logit, pch = "|")
```

Logit 是一个受到非常广泛应用的模型，它十分简单、计算速度非常快，而且具有很强的可解释性。虽然 Logit 模型已经由很好的预测分类能力，但如果我们仅仅关注这一预测准确性这一指标，可能还有其它模型有更佳的表现。

## 线性判别分析（LDA）

Fisher（1936）和 Welch（1939）分析了获得最优判别准则的方式。

由贝叶斯法则：

$$
\operatorname{Pr}\left[Y=C_{\ell} | X\right]=\frac{\operatorname{Pr}\left[Y=C_{\ell}\right] \operatorname{Pr}\left[X | Y=C_{\ell}\right]}{\sum_{\ell=1}^{C} \operatorname{Pr}\left[Y=C_{\ell}\right] \operatorname{Pr}\left[X | Y=C_{\ell}\right]}
$$

对于二分类问题，如果：

$$
\operatorname{Pr}\left[Y=C_{1}\right] \operatorname{Pr}\left[X | Y=C_{1}\right]>\operatorname{Pr}\left[Y=C_{2}\right] \operatorname{Pr}\left[X | Y=C_{2}\right]
$$

我们就将 X 分入类别1，否则分入类别2。

为了计算 $\operatorname{Pr}\left[X | Y=C_{\ell}\right]$，我们假设预测变量服从多元正态分布，分布的两个参数为：多维均值向量 $\boldsymbol{\mu}_{\ell}$ 和协方差矩阵 $\boldsymbol{\Sigma}_{\ell}$，假设不同组的均值向量不同且协方差相同，用每一类观测样本均值 $\bar{x}_{\ell}$ 估计 $\boldsymbol{\mu}_{\ell}$，用样本协方差 $\boldsymbol{S}$ 估计理论协方差矩阵 $\boldsymbol{\Sigma}$，将样本观测 $\mu$ 代入 $X$，第 $\ell$ 组的线性判别函数为：

$$
X^{\prime} \boldsymbol{\Sigma}^{-1} \boldsymbol{\mu}_{\ell}-0.5 \boldsymbol{\mu}_{\ell}^{\prime} \boldsymbol{\Sigma}^{-1} \boldsymbol{\mu}_{\ell}+\log \left(\operatorname{Pr}\left[Y=C_{\ell}\right]\right)
$$

当我们仔细观察线性判别函数时,我们会发现 Fisher 的线性判别方法有两点缺陷：

1. 而且，由于线性判别分析的数学构造，随着预测变量数目的增加，预测的类别概率越来越接近0和1。这意味这，在我们的数据集下，由于变量较多，如前文所述的调整概率阈值的方法可能有效性会降低。这在单纯分类**逾期**和**信用良好**的持卡人时可能并不是问题，但在需要进一步平衡灵敏度和特异度以达到更好效果时将很难进行。

2. 由于线性判别分析的结果取决于协方差矩阵的逆，且只有当这个矩阵可逆时才存在唯一解。这意味着样本量要大于变量个数 ^[一般要求数据集含有至少预测变量5——10倍的样本]，且变量必须尽量相互独立。而在我们的数据集中，变量之间有很强的多重共线性，这在一定程度上会降低预测的准确性。

```{r}
set.seed(1)
logit <- train(SeriousDlqin2yrs ~ ., data = training, 
                 method = "lda", 
                 trControl = fitControl,
               preProc = c("center", "scale"),)
logit
logit$results

trellis.par.set(caretTheme())
plot(logit)

trellis.par.set(caretTheme())
plot(logit, metric = "Kappa")

trellis.par.set(caretTheme())
densityplot(logit, pch = "|")
```

## 偏最小二乘判别分析（PLSDA）

由于 LDA 不太适合多重共线性的变量，我们可以试着使用主成分分析压缩变量空间的维度，但 PCA 可能无法识别能将样本分类的较好变量组合，且由于没有涉及被解释变量的分类信息（无监督），很难通过 PCA 找到一个最优化的分类预测。

所以，我们使用偏最小二乘判别分析来进行分类。Berntsson 和 Wold（1986）将偏最小二乘应用在了问题中，起名为偏最小二乘判别分析（PLSDA）。尽管 Lie 和 Rayens（2007）指出，在降维非必须且建模目的时分类的时候，LDA 一定优于 PLS，但我们希望在降维之后，PLS 的表现能超过 LDA。

```{r}
set.seed(1)
logit <- train(SeriousDlqin2yrs ~ ., data = training, 
                 method = "pls", 
                 trControl = fitControl)
logit
logit$results

trellis.par.set(caretTheme())
plot(logit)

trellis.par.set(caretTheme())
plot(logit, metric = "Kappa")

trellis.par.set(caretTheme())
densityplot(logit, pch = "|")
```

缺点：

1. 


## 模型间的比较

我们对 ... 和 ... 模型进行比较，两个模型都使用相同的重抽样方法估计各自的模型表现。 ^[由于设置的随机数种子相同，故不同模型使用的重抽样样本完全一致。]

```{r}
resamp = resamples(list(GBM = gbm, SVM = svm, Logit = logit))
summary(resamp)
summary(diff(resamp))
ggplot(resamp,
       models = c("GBM", "SVM", "Logit"),
       metric = "Accuracy",
       conf.level = 0.95) +
  theme_bw()
```

分析图，在 95% 的置信区间下，.....

分析p值

.....结果表明，X个模型表现十分接近。

# 全部样本 logit regression

因为 logit 模型相对简单，求解速度快，且具有较强的可解释性，故我们使用 logit 模型对全部完整的样本进行拟合。

```{r}
set.seed(1)
inTraining <- createDataPartition(dat_complete$SeriousDlqin2yrs, p = .75, list = FALSE)
train <- dat_complete[inTraining,]
test <- dat_complete[-inTraining,]
```

```{r}
logit2 = glm(SeriousDlqin2yrs ~ ., data = train, family = binomial(link = "logit"))
summary(logit2)
```

分析逻辑回归的方向、变量显著性。

## 预测

```{r}
probability = predict(logit2, test, type = "response")
summary(probability)

distribution = as.data.frame(probability)
distribution = cbind(distribution, group = test$SeriousDlqin2yrs)
ggplot(distribution, aes(x = probability, fill = group)) +
  geom_density(alpha = 0.3) + 
  theme_minimal() +
  scale_fill_manual(values = c("#037418", "darkred"))

testPred = probability
length(testPred[testPred > 0.5]) / length(testPred)
testPred[testPred > 0.5] = 1
testPred[testPred <= 0.5] = 0
testPred = as.factor(testPred)
```

可以看出，对于真实情况为信用好的持卡人，我们预测出的逾期概率值的分布是有偏的，大多数预测概率的非常低。然而，比较之下，对于真实情况为逾期的持卡人，我们预测出的逾期概率值的分布则显得较为均匀。

为此，我们猜想：**我们的模型将信用好的持卡人错认为逾期的概率较低，但是较难识别出逾期的客户。**

为了验证我们的猜想，我们使用.....（以下）

## 混淆矩阵与验证结果

灵敏度（Sensitivity）

$$\text{灵敏度} = \frac{\text{正确判定为“逾期”的样本数量}}{观测到的“逾期”的样本数量}$$

特异度（Specificity）

$$\text{灵敏度} = \frac{\text{正确判定为“正常”的样本数量}}{观测到的“正常”的样本数量}$$

假阳性率为 1 - 特异度

```{r}
confusion = confusionMatrix(data = test$SeriousDlqin2yrs,
                reference = testPred,
                positive = "1")
confusion
```

可以看到：尽管准确率达到了 `r round(confusion$overall[1], 3)`, 但是还低于`r round(confusion$overall[5], 3)`的无信息率准确度（No Information Rate）。

从灵敏度和特异度来看：.....

> 待补充

验证了我们的猜测：**当持卡人逾期时，模型不一定能准确预测到。**

> 如果模型的准确度稳定在一个水平,通常会在灵敏度和特异度之间做一个权衡。直觉上,增加灵敏度会使特异度下降,因为更多的样本被预测为“发生”。当不同类型的错误对应惩罚不同时,在灵敏度和特异度间做出潜在权衡或许是合理的。在过滤垃圾邮件时我们通常关注特异度,如果家人和同事的邮件能不被删除,大多数人愿意接受看一些垃圾邮件。

> 这段话要进行改写，垃圾邮件要改为我们的数据案例，注意规避查重。

为了评估二者间权衡，我们使用接受者操作特征（ROC）曲线。

## 接受者操作特征（ROC）曲线

ROC曲线 (Altman和 Bland1994; Brown和 Davis2006; Fawcett2006).... ^[ROC曲线是一个较为常用的方法，它给出了一系列连续数据点，便于确定一个有效的阈值，将超过某个阈值的值表示一个特定的事件。]


```{r}
rocCurve = roc(response = test$SeriousDlqin2yrs,
               predictor = probability,
               levels = rev(levels(test$SeriousDlqin2yrs)),
               plot = TRUE,
               print.thres=TRUE, print.auc=TRUE)
auc(rocCurve)
```

前文计算灵敏度和特异度时，我们默认50%概率阈值。为了捕获更多真阳性样本的方式提高灵敏度，我们可以通过降低阈值的方法。将阈值降低至 XX, 此时，灵敏度从 XX 提高到了 XX，特异度.....。也就是说，降低阈值有利于我们识别出更多逾期的持卡人，但同时也会使误判的几率上升。


## 提升图

```{r}
test = cbind(test, probability)
liftCurve = lift(SeriousDlqin2yrs ~ probability, data = test[1:1000,])
plot(liftCurve)
```


在实际操作中，我们可以通过确定不同的阈值来达到不同的效果，例如：

1. 在进行交易风控、信用卡降额的自动化系统构建时，通过确定较高的阈值以提高特异度，避免错判。
2. 在进行逾期自动化预测以便于进一步调查时，通过降低阈值的方式提高灵敏度，以检测出更多潜在逾期持卡人。
3. 通过平衡错判的成本与查漏的损失，确定适中的阈值以谋求商业利益最大化。



# 附录

## 数据

```{r}
str(dat)
```
