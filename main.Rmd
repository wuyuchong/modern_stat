---
title: "现代统计软件论文"
author:
  - 吴宇翀
  - 高思琴
  - 陈蔚
documentclass: ctexart
output:
  rticles::ctex:
    fig_caption: yes
    number_sections: yes
    template: template.tex
  word_document: default
classoption: "hyperref,"
geometry: margin=1in
csl: chinese-gb7714-2005-numeric.csl
bibliography: reference.bib
header-includes:
   - \usepackage{graphicx}
   - \usepackage{float}
   - \usepackage{indentfirst}
   - \setlength{\parindent}{4em}
logo: "cufe.jpg"
---

```{r setup, include=FALSE, message=FALSE}
knitr::opts_chunk$set(fig.pos = 'H', echo = FALSE, warning = FALSE, message = FALSE)
library(ggplot2)
library(caret)
library(kernlab)
library(pROC)
library(knitr)
library(magrittr)
# base_family = 'STXihei'
# bibliography: cite.bib
```

# 摘要{-}

信用卡业务，是商业银行的核心业务；与此同时，信用卡的风险控制，一直以来都是信用卡业务最为密切关注的重要一环。信用卡逾期预测算法，直接为银行的信用卡风控业务提供支持。在此研究中，我们使用公开数据集，通过建立多种算法模型，计算预测的**信用卡逾期概率**。

我们建立简单的 Logit 回归以初步解释各个变量的效应。在使用混淆矩阵得出**灵敏度**和**特异度**之后，我们使用 **ROC 曲线**结合业务情形在两者之间进行权衡。

在使用相同的重抽样方法进行重复 5 次的 10 折**交叉验证**的前提下，我们将准确率和 Kappa 作为衡量指标，比较了 **Logit、线性判别、偏最小二乘判别、支持向量机、随机梯度助推模型**的优劣。

在模型选择上，**GBM**模型具有最好的效果，**Logit**模型次之。然而，在模型的应用方面，我们更加倾向于使用计算速度较快、可解释性强的 Logit 模型。

在变量选择上，数据集中最重要的变量描述的是持卡人过去是否有信用卡逾期的先例，它们很好地反映出借贷者的信誉情况。而重要程度最低的三个变量分别是“家属人数”“负债比率”和“月收入”，即这些变量并不直接反应持卡人的还贷习惯，影响较小。

\ 

\ 

\ 

\ 

关键词： **信用卡逾期**， **分类预测模型**， **机器学习**， **变量选择**， **模型比较**

\newpage

\tableofcontents

# 背景

银行在市场经济中扮演着至关重要的角色。他们决定谁可以得到资金，并需要什么样的条件，他们可以做出投资决定，当然也可以取消投资决定。在当今的社会条件下，为了使市场和生活正常运转，个人和公司常常需要获得信贷。作为新兴的消费工具，信用卡已经成为许多人的必备。然而信用卡一旦逾期，会给银行带来很大的风险。所以识别和预测信用卡是否将会逾期成为银行信用卡风控部门的重要工作。  

信用评分算法是银行用来判断是否应该发放信用卡的一种重要解决方案，通过它可以对违约概率进行预测。银行利用持卡人的各种指标，通过预测持卡人遭遇财务困难的可能性，来提高信用评分的准确性。我们通过建立多个模型来帮助信用卡风控部门做出最佳的商业决策。

# 数据集说明

我们使用一个公开的数据集 ^[数据来源: https://www.kaggle.com/c/GiveMeSomeCredit/overview] ，它有 11 个变量，150000 个观测。

```{r}
dat = read.csv("data.csv")
dat = dat[,-1]
dat$SeriousDlqin2yrs = as.factor(dat$SeriousDlqin2yrs)
```

```{r}
explain = read.csv("dictionary_chinese.csv", header = TRUE)
kable(explain, caption = "变量描述解释")
```

# 数据预处理

1. 由于样本量已经足够大，我们删除所有包含缺失值的观测。
2. 由于**信用卡和个人信贷额度的总余额**和**负债比率**两个指标为百分比，我们将这两个指标中小于0的数据调整为0，将大于1的数据调整为1。

```{r}
dat$RevolvingUtilizationOfUnsecuredLines[which(dat$RevolvingUtilizationOfUnsecuredLines < 0)] = 0
dat$RevolvingUtilizationOfUnsecuredLines[which(dat$RevolvingUtilizationOfUnsecuredLines > 1)] = 1
dat$DebtRatio[which(dat$DebtRatio < 0)] = 0
dat$DebtRatio[which(dat$DebtRatio > 1)] = 1
dat_complete = dat[complete.cases(dat),]
```

# 描述分析

## 年龄

```{r fig.align="center", fig.cap="信用卡逾期与否两类人群的年龄分布（红色代表逾期）", out.width="80%"}
ggplot(dat_complete, aes(x = age, fill = SeriousDlqin2yrs)) +
  geom_density(alpha = 0.3) + 
  theme_minimal() +
  scale_fill_manual(values = c("#037418", "darkred"))
```

从上图中我们可以看到，信用卡逾期与否的两类人群年龄上有着较为明显的差别。信用卡逾期者普遍年龄较小，这可能与信用卡使用者的使用习惯有关。

相比年龄较大的人群，年轻人群当中奉行享乐主义者较多，一旦控制不当或者出现突发情况，就容易通过透支信用卡来填补空缺，而一旦信用卡数量过多而导致忘记还款，就会造成信用卡逾期的情况。除此之外，年龄较小人群工作稳定性不足，可能会有创业资金链破裂或者因为初入社会工资无法满足日常生活的问题，这也会导致无法及时还款。

## 债务数量

我们在信用好和差的持卡人中各抽取1000人，且由于数量多于5的持卡人非常少，为了方便画图，我们删去这些样本。

```{r fig.align="center", fig.cap="信用卡逾期与否两类人群的债务数量（红色代表逾期）", out.width="80%"}
dat_process = dat_complete[which(dat_complete$NumberRealEstateLoansOrLines < 5),]
good = dat_process[which(dat_process$SeriousDlqin2yrs == 0),]
bad = dat_process[which(dat_process$SeriousDlqin2yrs == 1),]
dat_process = rbind(good[1:1000,], bad[1:1000,])
ggplot(dat_process, aes(x = NumberRealEstateLoansOrLines, fill = SeriousDlqin2yrs)) +
  geom_histogram(stat = "count", alpha = 0.6) + 
  theme_minimal() +
  scale_fill_manual(values = c("#037418", "darkred")) +
  facet_grid(cols = vars(SeriousDlqin2yrs)) +
  labs(y = "percentage")
```

通过统计图可知，在抵押贷款和房贷上，总体来看，大部分人的贷款数量都在3份以下。信用较好的持卡人相比信用较差的持卡人，没有贷款的比例更小、有1-2份贷款的比例更大，有更多贷款的比例更小。这表明，对于大多数持卡人而言，有1-2份贷款是合理的，这也是持卡人有一定财力进行还款的体现；然而，持卡人若同时背负过多份贷款，则会有很大的还款压力，信用卡还款逾期概率上升。

## 月收入

且由于月收入高于30000的持卡人非常少，为了方便画图，我们删去这些样本。

```{r fig.align="center", fig.cap="信用卡逾期与否两类人群的月收入（红色代表逾期）", out.width="80%"}
dat_process = dat_complete[which(dat_complete$MonthlyIncome < 30000),]
ggplot(dat_process, aes(x = SeriousDlqin2yrs, y = MonthlyIncome, fill = SeriousDlqin2yrs)) +
  geom_violin(alpha = 0.3) + 
  theme_minimal() +
  scale_fill_manual(values = c("#037418", "darkred"))
```

根据图可得，大部分信用卡适用人群的月收入在10000美元以内。图中信用卡逾期与否的两个图形对比后可得信用卡逾期的持卡人中，收入在5000元以下的人数比较多，这可能是由于收入较低的人群收入剩余较少，一旦不可控因素月开支增加，可能无法及时还款，收入10000元以上信用卡逾期人数少的原因正好与之相反。由月收入的密度分布可得，逾期的人群更加集中在3000美元的月收入左右；而按时还贷的人群工资范围则比较平均，集中性弱一些。其原因可能是国家政策规定工资不得低于一定数额，各地的最低工资标准虽然不同，但是低收入人群的工资范围是相似的，某一收入范围对于现在的生活开销来说比较吃力，每月开销需要控制才能不超于预算，该类人群信用卡逾期概率大。

# Logit 回归

## 拟合

因为 logit 模型相对简单，求解速度快，且具有较强的可解释性，故我们使用 logit 模型对样本进行拟合。

我们对样本进行随机抽样，划分为 75% 的训练集和 25% 的测试集（验证集）。

```{r}
set.seed(1)
inTraining <- createDataPartition(dat_complete$SeriousDlqin2yrs, p = .75, list = FALSE)
train <- dat_complete[inTraining,]
test <- dat_complete[-inTraining,]
```

```{r}
logit2 = glm(SeriousDlqin2yrs ~ ., data = train, family = binomial(link = "logit"))
logit2_sum = summary(logit2)
translate = as.character(explain$变量名)
translate[1] = "（截距）"
rownames(logit2_sum$coefficients) = translate
kable(logit2_sum$coefficients, caption = "Logit回归系数表", digit = 2)
```

可以看到，所有系数的 p 值在四舍五入后都为0，变量全部显著。自变量对因变量的正负向作用分析如下：

无担保放款的循环利用次数越多，逾期可能性越高。由于个人信用总额度大，借款的数量多，从而导致还款不及时或者到指定日期还款能力不足。

年龄越大逾期可能性越小，但影响程度不高。年龄越大工作生活的状态越稳定，心智更加成熟，收入会比年龄小的人群更多，需要使用信用卡借款的可能性越低。

过去两年间逾期30-59天的次数越多，逾期的可能性越高。有过短时间逾期经历的人群对截止日期的敏感程度会降低，重视程度也会下降，从而导致超过还款日期的可能性增高。

负债比率越高，逾期的可能性越高。日常开销和债务占收入的比例越大，可支配金额越少，此时可能个人基本生活开销都会出现问题，还款的可能性降低。

月收入的增加会使得逾期的可能性降低。月收入越高，可支配金额越多，还款能力越强，但是否及时还款还是需要根据个人还款习惯。即使收入增加，借贷人忘记还款日期也依然会造成逾期。

未偿还贷款数量越多会导致逾期的可能性增加。有大量负债说明资金链已经出现问题，需要偿还的债务很多，及时归还信用卡贷款的可能性低。

90天逾期次数越多，逾期的可能性越高。在这种情况下，持卡人出于各种自身原因长期拖欠，陷入资金不正常循环。


## 预测

```{r fig.align="center", fig.cap="预测的逾期概率值（红色代表已知为逾期）", out.width="80%"}
probability = predict(logit2, test, type = "response")
distribution = as.data.frame(probability)
distribution = cbind(distribution, group = test$SeriousDlqin2yrs)
ggplot(distribution, aes(x = probability, fill = group)) +
  geom_density(alpha = 0.3) + 
  theme_minimal() +
  scale_fill_manual(values = c("#037418", "darkred"))

testPred = probability
testPred[testPred > 0.5] = 1
testPred[testPred <= 0.5] = 0
testPred = as.factor(testPred)
```

可以看出，对于真实情况为信用好的持卡人，我们预测出的逾期概率值的分布是有偏的，大多数预测概率的非常低。然而，比较之下，对于真实情况为逾期的持卡人，我们预测出的逾期概率值的分布则显得较为均匀。

为此，我们猜想：**我们的模型将信用好的持卡人错认为逾期的概率较低，但是较难识别出逾期的客户。**

为了验证我们的猜想，我们使用混淆矩阵来计算预测模型的灵敏度和特异度。

## 混淆矩阵与验证结果

灵敏度（Sensitivity）

$$\text{灵敏度} = \frac{\text{正确判定为“逾期”的样本数量}}{\text{观测到的“逾期”的样本数量}}$$

特异度（Specificity）

$$\text{灵敏度} = \frac{\text{正确判定为“正常”的样本数量}}{\text{观测到的“正常”的样本数量}}$$

假阳性率为 1 - 特异度

```{r}
confusion = confusionMatrix(data = test$SeriousDlqin2yrs,
                reference = testPred,
                positive = "1")
kable(as.data.frame(confusion$table), caption = "混淆矩阵表")
```

```{r}
table = as.data.frame(confusion$overall)
names(table) = c("指标值")
table = t(table)
rownames(table) = NULL
kable(table, caption = "验证结果表", digit = 3)
```

可以看到：尽管准确率达到了 `r round(confusion$overall[1], 3)`, 但是还低于`r round(confusion$overall[5], 3)`的无信息率准确度（No Information Rate）。

```{r}
table = as.data.frame(confusion$byClass[1:5])
names(table) = c("指标值")
table = t(table)
kable(table, caption = "灵敏度和特异度等指标表", digit = 3)
```

从灵敏度和特异度来看：55.8% 的将会逾期的客户会被模型成功捕捉到；对于模型捕捉到的客户，只有 6.7% 的误判率。这验证了我们的猜测：**当持卡人逾期时，模型不一定能准确预测到；不过模型预测认为是逾期的客户绝大部分情况下的确会发生逾期**

> 如果模型的准确度稳定在一个水平,通常会在灵敏度和特异度之间做一个权衡。直觉上，增加灵敏度会使特异度下降，因为更多的样本被预测为“发生”。当不同类型的错误对应惩罚不同时,在灵敏度和特异度间做出潜在权衡或许是合理的。在过滤垃圾邮件时我们通常关注特异度,如果家人和同事的邮件能不被删除,大多数人愿意接受看一些垃圾邮件。

> 陈蔚：这段话要进行改写，垃圾邮件要改为我们的数据案例，注意规避查重。

---

## 接受者操作特征（ROC）曲线

为了在灵敏度和特异度二者间权衡，我们使用接受者操作特征（ROC）曲线。

---

ROC曲线 (Altman 和 Bland 1994; Brown 和 Davis 2006; Fawcett 2006) @Altman1994Diagnostic @Brown2006Receiver @Fawcett2006An were designed as a general method that, given a collection of continuous data points, determine an effective threshold such that values above the threshold are indicative of a specific event. ROC curve can be used for determining alternate cutoffs for class probabilities.（陈蔚：待翻译） ^[ROC曲线是一个较为常用的方法，它给出了一系列连续数据点，便于确定一个有效的阈值，将超过某个阈值的值表示一个特定的事件。]

---

```{r fig.align="center", fig.cap="Logit 模型的 ROC 曲线", out.width="80%"}
rocCurve = roc(response = test$SeriousDlqin2yrs,
               predictor = probability,
               levels = rev(levels(test$SeriousDlqin2yrs)),
               plot = TRUE,
               print.thres=TRUE, print.auc=TRUE)
```

前文计算灵敏度和特异度时，我们默认 50% 概率阈值。为了捕获更多真阳性样本的方式提高灵敏度，我们可以通过降低阈值的方法。将阈值降低至 6.3% , 此时，灵敏度从 55.8% 提高到了 71.9% ，特异度从 93.3% 降低到了 74.1%。

也就是说，降低阈值有利于我们识别出更多逾期的持卡人，但同时也会使误判的几率上升。

在实际操作中，我们可以通过**确定不同的阈值来达到不同的效果**，例如：

1. 在进行交易风控、信用卡降额的自动化系统构建时，通过确定较高的阈值以提高特异度，避免错判。
2. 在进行逾期自动化预测以便于进一步调查时，通过降低阈值的方式提高灵敏度，以检测出更多潜在逾期持卡人。
3. 通过平衡错判的成本与查漏的损失，确定适中的阈值以谋求商业利益最大化。

# 模型选择

## 抽样、训练与评价指标

```{r}
set.seed(1)
inTraining <- createDataPartition(dat_complete$SeriousDlqin2yrs, p = .01, list = FALSE)
training <- dat_complete[inTraining,]

fitControl <- trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           ## repeated ten times
                           repeats = 5)
```

由于数据集样本量过大，难以完成较为复杂的模型求解。 ^[由于条件所限，本研究小组只有单台计算机的算力。在有分布式计算的环境下，可能不需要此步操作。]我们从总样本中随机抽取 1% 的数据用于各种模型的训练和验证。

我们使用10折交叉验证，重复5次的方法进行重抽样。

我们使用 Kappa 和准确率作为模型的评价指标。

Kappa 统计量（Cohen 1960） @Cohen1960A 最初是一个用来评估两个估价者评估结果的一致性，同时也考虑到了由偶然情况引起的准确性误差。

$$\mathrm{Kappa}=\frac{O-E}{1-E}$$

---

> 在上式中，O是观测的准确性，E是基于混淆矩阵边缘计数得到的期望准确性。该统计量取值在-1和1之间;0值表示观测类与预测类之间没有一致性，1值表示模型的预测与观测类完全一致。负值表示预测与事实相反，但在建立预测模型过程中绝对值大的负值很少出现。当各类分布相同时，总精确度与 Kappa是成比例的。取决于具体情况，Kappa值在0.30到0.50之间代表合理的一致性。（Agresti 2002）

> 陈蔚：这段话要进行语序修改，规避查重。

---

## Logit 回归

```{r}
set.seed(1)
logit <- train(SeriousDlqin2yrs ~ ., data = training, 
                 method = "glm", 
                 trControl = fitControl)
table = logit$results
rownames(table) = NULL
kable(table, caption = "在重抽样下 Logit 模型的表现", digits = 3)
```

Logit 是一个受到非常广泛应用的模型，它十分简单、计算速度非常快，而且具有很强的可解释性。虽然 Logit 模型已经有很好的预测分类能力，但如果我们仅仅关注这一预测准确性这一指标，可能还有其它模型有更佳的表现。

## 线性判别分析（LDA）

Fisher（1936）@fisher36lda 和 Welch（1939）@WELCH1939 分析了获得最优判别准则的方式。

由贝叶斯法则：

$$
\operatorname{Pr}\left[Y=C_{\ell} | X\right]=\frac{\operatorname{Pr}\left[Y=C_{\ell}\right] \operatorname{Pr}\left[X | Y=C_{\ell}\right]}{\sum_{\ell=1}^{C} \operatorname{Pr}\left[Y=C_{\ell}\right] \operatorname{Pr}\left[X | Y=C_{\ell}\right]}
$$

对于二分类问题，如果：

$$
\operatorname{Pr}\left[Y=C_{1}\right] \operatorname{Pr}\left[X | Y=C_{1}\right]>\operatorname{Pr}\left[Y=C_{2}\right] \operatorname{Pr}\left[X | Y=C_{2}\right]
$$

我们就将 X 分入类别1，否则分入类别2。

为了计算 $\operatorname{Pr}\left[X | Y=C_{\ell}\right]$，我们假设预测变量服从多元正态分布，分布的两个参数为：多维均值向量 $\boldsymbol{\mu}_{\ell}$ 和协方差矩阵 $\boldsymbol{\Sigma}_{\ell}$，假设不同组的均值向量不同且协方差相同，用每一类观测样本均值 $\bar{x}_{\ell}$ 估计 $\boldsymbol{\mu}_{\ell}$，用样本协方差 $\boldsymbol{S}$ 估计理论协方差矩阵 $\boldsymbol{\Sigma}$，将样本观测 $\mu$ 代入 $X$，第 $\ell$ 组的线性判别函数为：

$$
X^{\prime} \boldsymbol{\Sigma}^{-1} \boldsymbol{\mu}_{\ell}-0.5 \boldsymbol{\mu}_{\ell}^{\prime} \boldsymbol{\Sigma}^{-1} \boldsymbol{\mu}_{\ell}+\log \left(\operatorname{Pr}\left[Y=C_{\ell}\right]\right)
$$

由于我们的分类只有两类，所以只有一个判别向量，不需要优化判别向量的数目，即不需要模型调优，计算速度较快。

当我们仔细观察线性判别函数时,我们会发现 Fisher 的线性判别方法有两点缺陷：

1. 而且，由于线性判别分析的数学构造，随着预测变量数目的增加，预测的类别概率越来越接近0和1。这意味这，在我们的数据集下，由于变量较多，如前文所述的调整概率阈值的方法可能有效性会降低。这在单纯分类**逾期**和**信用良好**的持卡人时可能并不是问题，但在需要进一步平衡灵敏度和特异度以达到更好效果时将很难进行。

2. 由于线性判别分析的结果取决于协方差矩阵的逆，且只有当这个矩阵可逆时才存在唯一解。这意味着样本量要大于变量个数 ^[一般要求数据集含有至少预测变量5——10倍的样本]，且变量必须尽量相互独立。而在我们的数据集中，变量之间有很强的多重共线性，这在一定程度上会降低预测的准确性。

```{r}
set.seed(1)
lda <- train(SeriousDlqin2yrs ~ ., data = training, 
                 method = "lda", 
                 trControl = fitControl,
               preProc = c("center", "scale"))
table = lda$results
rownames(table) = NULL
kable(table, caption = "在重抽样下 LDA 模型的表现", digits = 3)
```

```{r fig.align="center", fig.cap="在重抽样下 LDA 模型的准确率分布", out.width="50%"}
trellis.par.set(caretTheme())
densityplot(lda, pch = "|")
```


## 偏最小二乘判别分析（PLSDA）

由于 LDA 不太适合多重共线性的变量，我们可以试着使用主成分分析压缩变量空间的维度，但 PCA 可能无法识别能将样本分类的较好变量组合，且由于没有涉及被解释变量的分类信息（无监督），很难通过 PCA 找到一个最优化的分类预测。

所以，我们使用偏最小二乘判别分析来进行分类。Berntsson 和 Wold（1986） @Peder1986Comparison 将偏最小二乘应用在了问题中，起名为偏最小二乘判别分析（PLSDA）。尽管 Liu 和 Rayens（2007） @Liu2007PLS 指出，在降维非必须且建模目的时分类的时候，LDA 一定优于 PLS，但我们希望在降维之后，PLS 的表现能超过 LDA。

我们只使用前十个 PLS 成分

```{r}
set.seed(1)
plsda <- train(SeriousDlqin2yrs ~ ., data = training, 
                 method = "pls", 
                 trControl = fitControl,
               tuneGrid = expand.grid(.ncomp = 1:10))
table = lda$results
rownames(table) = NULL
kable(table, caption = "在重抽样下 PLSDA 模型的表现", digits = 3)
```

```{r fig.align="center", fig.cap="Kappa 指标随主成分个数的变化", out.width="49%", fig.show='hold'}
trellis.par.set(caretTheme())
plot(plsda, metric = "Kappa")
plot(plsda)
```

我们可以看到 Kappa 指标随主成分个数的增多而先上升，后基本保持不变。可见，在此模型中，选取前 5 个主成分效率最高。

```{r fig.align="center", fig.cap="变量重要程度", out.width="80%"}
plsImp = varImp(plsda, scale = FALSE)
table = data.frame(variables = rownames(plsImp$importance), importence = plsImp$importance$Overall)
ggplot(table, aes(x = reorder(variables, importence), y = importence)) +
  geom_col() +
  theme_minimal() +
  coord_flip() +
  labs(x = "variables")
```

由上图所示，各个变量的重要程度有明显不同。排在前三名的是“过去逾期30-59天的次数”, “逾期超过90天的次数”和“过去两年内逾期60-89天的次数”。这三个变量都属于同一类型的变量，它们描述的都是借贷者过去是否有信用卡逾期的先例，它们代表的数据能很好地反映出借贷者的信誉情况。过去出现过逾期的先例，那么未来信用卡逾期的可能性就大大增加。而重要程度最低的三个变量分别是“家属人数”“负债比率”和“月收入”。这三个变量与个人信誉的关系不大，属于外界因素。即使家属人数多，负债比率高，月收入低，借贷人依旧可以通过合理规划及时还款。即借贷人如果有良好的还贷习惯，这些变量的影响较低。

## SVM

Logit、LDA、PLSDA 本质上都是线性模型，即模型结构产生线性类边界，这一类模型的优点是不太会受到无信息变量的干扰。然而，在我们的数据中，并没有存在大量无信息变量的情况，所以我们考虑使用非线性模型进行训练。

```{r}
set.seed(1)
svm <- train(SeriousDlqin2yrs ~ ., data = training, 
                 method = "svmRadial", 
                 trControl = fitControl,
            tuneLength = 5)
kable(svm$results, caption = "在重抽样下 SVM 模型的表现", digits = 3)
```

```{r fig.align="center", fig.cap="调优参数不同取值下的准确率和 Kappa 指标变化", out.width="49%", fig.show='hold'}
trellis.par.set(caretTheme())
plot(svm)
plot(svm, metric = "Kappa")
```

---

分析

---

## 随机梯度助推法（GBM）

第三类被广泛应用的模型是分类树与基于规则的模型，在此，我们使用助推法这种树结构与规则的融合方法。

Friedman等（2000） @Ben2000Tissue 发现分类问题可以当作是正向分布可加模型，通过最小化指数损失函数实现分类。

首先我们设定样本预测初始值为对数发生：

$$
f_{i}^{(0)}=\log \frac{\hat{p}}{1-\hat{p}}
$$

其中，$f(x)$ 是模型的预测值，$\hat{p}_{i}=\frac{1}{1+\exp [-f(x)]}$

接着从 $j = 1$ 开始进行迭代：

1. 计算梯度 $z_{i}=y_{i}-\hat{p}_{i}$
2. 对训练集随机抽样
3. 基于子样本，用之前得到的残差作为结果变量训练树模型
4. 计算终结点 Pearson 残差的估计 $r_{i}=\frac{1 / n\sum_{i}^{n}\left(y_{i}-\hat{p}_{i}\right)}{1 / n \sum_{i}^{n} \hat{p}_{i}\left(1-\hat{p}_{i}\right)}$
5. 更新当前模型 $f_{1}=f_{i}+\lambda f_{i}^{(j)}$

```{r include=FALSE}
set.seed(1)
gbm <- train(SeriousDlqin2yrs ~ ., data = training, 
                 method = "gbm", 
                 trControl = fitControl)
kable(gbm$results, caption = "在重抽样下 GBM 模型的表现", digits = 3)
```

```{r fig.align="center", fig.cap="调优参数和迭代次数不同取值下的准确率和 Kappa 指标变化", out.width="49%", fig.show='hold'}
trellis.par.set(caretTheme())
plot(gbm)

trellis.par.set(caretTheme())
plot(gbm, metric = "Kappa")
```

---

分析

---

```{r fig.align="center", fig.cap="在重抽样下 GBM 模型的准确率分布", out.width="50%"}
trellis.par.set(caretTheme())
densityplot(gbm, pch = "|")
```

## 模型间的比较

我们对训练的4个不同的模型进行比较，所有模型都使用相同的重抽样方法估计各自的模型表现。且由于设置的随机数种子相同，故不同模型使用的重抽样样本完全一致。 ^[重抽样 50 次：10 折交叉验证重复 5 次]

```{r}
resamp = resamples(list(LDA = lda, PLSDA = plsda, SVM = svm, GBM = gbm, Logit = logit))
s1 = summary(resamp)
s2 = summary(diff(resamp))
```

```{r fig.align="center", fig.cap="模型间 Kappa 的比较（0.95 置信区间）", out.width="80%", fig.height=3, fig.width=6}
ggplot(resamp,
       models = c("LDA", "PLSDA", "GBM", "Logit"),
       metric = "Kappa",
       conf.level = 0.95) +
  theme_bw()
```

在**Kappa**这一效果衡量指标下，GBM 有着最好的效果，Logit 模型次之，PLSDA 模型表现最差。

```{r fig.align="center", fig.cap="模型间准确率的比较（0.95 置信区间）", out.width="80%", fig.height=3, fig.width=6}
ggplot(resamp,
       models = c("LDA", "PLSDA", "SVM", "GBM", "Logit"),
       metric = "Accuracy",
       conf.level = 0.95) +
  theme_bw()
```

# 总结

## 模型选择

在**准确率**这一效果衡量指标下，从偏差的角度来看，GBM 有着最好的效果，Logit 模型次之；从方差的角度来看，PLSDA 和 SVM 模型具有明显较小的方差；LDA 模型则表现不佳。

综合来看，**GBM**模型具有最好的效果，**Logit**模型次之。然而，在模型的应用方面，我们更加倾向于使用计算速度较快、可解释性强的 Logit 模型。

## 变量选择

根据 PLSDA 的结果，数据集中最重要的变量描述的是持卡人过去是否有信用卡逾期的先例，它们很好地反映出借贷者的信誉情况。过去出现过逾期的先例，那么未来信用卡逾期的可能性就大大增加。

而重要程度最低的三个变量分别是“家属人数”“负债比率”和“月收入”。这三个变量与个人信誉的关系不大，属于外界因素。即使家属人数多，负债比率高，月收入低，持卡人依旧可以通过合理规划及时还款。即这些变量并不直接反应持卡人的还贷习惯，影响较低。

# 参考文献

<div id="refs"></div>

# 附录

## 数据

```{r}
str(dat)
```

## 模型间的比较

### 模型间准确率和 Kappa 的比较

```{r}
kable(s1$statistics$Accuracy, caption = "模型间准确率的比较", digit = 3)
```

```{r}
kable(s2$table$Accuracy, caption = "模型间准确率差异矩阵", digit = 3)
```

```{r}
kable(s1$statistics$Kappa, caption = "模型间 Kappa 的比较", digit = 3)
```

```{r}
kable(s2$table$Accuracy, caption = "模型间Kappa差异矩阵", digit = 3)
```

## Logit 回归结果

```{r}
logit2_sum
```



