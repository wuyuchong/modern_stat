---
title: "现代统计软件论文"
author:
  - 吴宇翀
  - 高思琴
  - 陈蔚
documentclass: ctexart
output:
  rticles::ctex:
    fig_caption: yes
    number_sections: yes
    toc: yes
classoption: "hyperref,"
---

```{r}
library(caret)
library(kernlab)
library(pROC)
```

# 摘要

识别与预测信用卡是否将会逾期（信用卡风控部门）

> 待完善

# 背景

识别与预测信用卡是否将会逾期（信用卡风控部门）

> 待完善

# 数据集说明

```{r}
dat = read.csv("data.csv")
dat = dat[,-1]
dat$SeriousDlqin2yrs = as.factor(dat$SeriousDlqin2yrs)
```

SeriousDlqin2yrs: 是否逾期。
RevolvingUtilizationOfUnsecuredLines：信用卡和个人信贷额度的总余额（百分比）*怀疑此翻译有误*
age：年龄
NumberOfTime30-59DaysPastDueNotWorse：过去2年，借款人逾期30-59天的次数
DebtRatio：负债比率（百分比）
MonthlyIncome：月收入
NumberOfOpenCreditLinesAndLoans：未偿还贷款数量（汽车贷款或抵押贷款等分期付款）和信贷额度（如信用卡）。
NumberOfTimes90DaysLate：借款人逾期90天或以上的次数。
NumberRealEstateLoansOrLines：抵押贷款和房地产贷款的数量。
NumberOfTime60-89DaysPastDueNotWorse：过去2年，借款人逾期60-89天的次数
NumberOfDependents：家庭中的家属人数（配偶，子女等）

> 数据集表格 dictionary


到英文网站上翻译 ^[数据来源: https://www.kaggle.com/c/GiveMeSomeCredit/overview]

> 待完善

## 异常值处理

1. 由于样本量已经足够大，我们删除所有包含缺失值的观测。
2. 由于**信用卡和个人信贷额度的总余额**和**负债比率**两个指标为百分比，我们将这两个指标中小于0的数据调整为0，将大于1的数据调整为1。

```{r}
dat$RevolvingUtilizationOfUnsecuredLines[which(dat$RevolvingUtilizationOfUnsecuredLines < 0)] = 0
dat$RevolvingUtilizationOfUnsecuredLines[which(dat$RevolvingUtilizationOfUnsecuredLines > 1)] = 1
dat$DebtRatio[which(dat$DebtRatio < 0)] = 0
dat$DebtRatio[which(dat$DebtRatio > 1)] = 1
dat_complete = dat[complete.cases(dat),]
```

## 基准正确率

```{r}
summary(dat_complete$SeriousDlqin2yrs)
1 - 8357 / 139974
```

# 模型选择

## 抽样

由于数据集样本量过大，难以完成较为复杂的模型求解。 ^[由于条件所限，本研究小组只有单台计算机的算力。在有分布式计算的环境下，可能不需要此步操作。]


```{r}
set.seed(1)
inTraining <- createDataPartition(dat_complete$SeriousDlqin2yrs, p = .01, list = FALSE)
training <- dat_complete[inTraining,]
```


Kappa 统计量（Cohen 1960）最初是一个用来评估两个估价者评估结果的一致性，同时也考虑到了由偶然情况引起的准确性误差。

$$\mathrm{Kappa}=\frac{O-E}{1-E}$$

> 在上式中，O是观测的准确性，E是基于混淆矩阵边缘计数得到的期望准确性。该统计量取值在-1和1之间;0值表示观测类与预测类之间没有一致性，1值表示模型的预测与观测类完全一致。负值表示预测与事实相反，但在建立预测模型过程中绝对值大的负值很少出现。当各类分布相同时，总精确度与 Kappa是成比例的。取决于具体情况，Kappa值在0.30到0.50之间代表合理的一致性。（Agresti 2002）

> 这段话要进行语序修改，规避查重。

## GBM

```{r include=FALSE}
set.seed(1)
fitControl <- trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           ## repeated ten times
                           repeats = 5)

set.seed(1)
gbm <- train(SeriousDlqin2yrs ~ ., data = training, 
                 method = "gbm", 
                 trControl = fitControl)
```

## SVM

```{r}
set.seed(1)
fitControl <- trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           ## repeated ten times
                           repeats = 5)

set.seed(1)
svm <- train(SeriousDlqin2yrs ~ ., data = training, 
                 method = "svmRadial", 
                 trControl = fitControl)
svm
svm$results

trellis.par.set(caretTheme())
plot(svm)

trellis.par.set(caretTheme())
plot(svm, metric = "Kappa")

trellis.par.set(caretTheme())
densityplot(svm, pch = "|")
```

## Logit

```{r}
set.seed(1)
fitControl <- trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           ## repeated ten times
                           repeats = 5)

set.seed(1)
logit <- train(SeriousDlqin2yrs ~ ., data = training, 
                 method = "glm", 
                 trControl = fitControl)
logit
logit$results

trellis.par.set(caretTheme())
plot(logit)

trellis.par.set(caretTheme())
plot(logit, metric = "Kappa")

trellis.par.set(caretTheme())
densityplot(logit, pch = "|")
```

## 模型间的比较

我们对 ... 和 ... 模型进行比较，两个模型都使用相同的重抽样方法估计各自的模型表现。 ^[由于设置的随机数种子相同，故不同模型使用的重抽样样本完全一致。]

```{r}
resamp = resamples(list(GBM = gbm, SVM = svm, Logit = logit))
summary(resamp)
summary(diff(resamp))
ggplot(resamp,
       models = c("GBM", "SVM", "Logit"),
       metric = "Accuracy",
       conf.level = 0.95) +
  theme_bw()
```

分析图，在 95% 的置信区间下，.....

分析p值

.....结果表明，X个模型表现十分接近。

# 全部样本 logit regression

因为 logit 模型相对简单，求解速度快，且具有较强的可解释性，故我们使用 logit 模型对全部完整的样本进行拟合。

```{r}
set.seed(1)
inTraining <- createDataPartition(dat_complete$SeriousDlqin2yrs, p = .75, list = FALSE)
train <- dat_complete[inTraining,]
test <- dat_complete[-inTraining,]
```

```{r}
logit2 = glm(SeriousDlqin2yrs ~ ., data = train, family = binomial(link = "logit"))
summary(logit2)
```

分析逻辑回归的方向、变量显著性。

## 预测

```{r}
probability = predict(logit2, test, type = "response")
summary(probability)

distribution = as.data.frame(probability)
distribution = cbind(distribution, group = test$SeriousDlqin2yrs)
ggplot(distribution, aes(x = probability, fill = group)) +
  geom_density(alpha = 0.3) + 
  theme_minimal() +
  scale_fill_manual(values = c("#037418", "darkred"))

testPred = probability
length(testPred[testPred > 0.5]) / length(testPred)
testPred[testPred > 0.5] = 1
testPred[testPred <= 0.5] = 0
testPred = as.factor(testPred)
```

可以看出，对于真实情况为信用好的持卡人，我们预测出的逾期概率值的分布是有偏的，大多数预测概率的非常低。然而，比较之下，对于真实情况为逾期的持卡人，我们预测出的逾期概率值的分布则显得较为均匀。

为此，我们猜想：**我们的模型将信用好的持卡人错认为逾期的概率较低，但是较难识别出逾期的客户。**

为了验证我们的猜想，我们使用.....（以下）

## 混淆矩阵与验证结果

灵敏度（Sensitivity）

$$\text{灵敏度} = \frac{\text{正确判定为“逾期”的样本数量}}{观测到的“逾期”的样本数量}$$

特异度（Specificity）

$$\text{灵敏度} = \frac{\text{正确判定为“正常”的样本数量}}{观测到的“正常”的样本数量}$$

假阳性率为 1 - 特异度

```{r}
confusion = confusionMatrix(data = test$SeriousDlqin2yrs,
                reference = testPred,
                positive = "1")
confusion
```

可以看到：尽管准确率达到了 `r round(confusion$overall[1], 3)`, 但是还低于`r round(confusion$overall[5], 3)`的无信息率准确度（No Information Rate）。

从灵敏度和特异度来看：.....

> 待补充

验证了我们的猜测：**当持卡人逾期时，模型不一定能准确预测到。**

> 如果模型的准确度稳定在一个水平,通常会在灵敏度和特异度之间做一个权衡。直觉上,增加灵敏度会使特异度下降,因为更多的样本被预测为“发生”。当不同类型的错误对应惩罚不同时,在灵敏度和特异度间做出潜在权衡或许是合理的。在过滤垃圾邮件时我们通常关注特异度,如果家人和同事的邮件能不被删除,大多数人愿意接受看一些垃圾邮件。

> 这段话要进行改写，垃圾邮件要改为我们的数据案例，注意规避查重。

为了评估二者间权衡，我们使用接受者操作特征（ROC）曲线。

## 接受者操作特征（ROC）曲线

ROC曲线 (Altman和 Bland1994; Brown和 Davis2006; Fawcett2006).... ^[ROC曲线是一个较为常用的方法，它给出了一系列连续数据点，便于确定一个有效的阈值，将超过某个阈值的值表示一个特定的事件。]








> 这段话要进行语序修改，规避查重。

```{r}
rocCurve = roc(response = test$SeriousDlqin2yrs,
               predictor = probability,
               levels = rev(levels(test$SeriousDlqin2yrs)))
auc(rocCurve)
plot(rocCurve, legacy.axes = TRUE)
```



## 提升图

```{r}
labs = 
```


# 附录

## 数据

```{r}
str(dat)
```
